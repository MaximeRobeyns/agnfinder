<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>3. Inference Overview &mdash; AGN Finder Documentation 0.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon-32x32.png"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="4. Inferring Galaxy Parameters (SAN)" href="san_inference.html" />
    <link rel="prev" title="2. Photometry Sampling" href="sampling.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #FFFFFF" >
            <a href="index.html" class="icon icon-home"> AGN Finder Documentation
            <img src="_static/base_logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">1. Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="sampling.html">2. Photometry Sampling</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">3. Inference Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#using-the-models">3.1. Using the Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#general-inference-parameters">3.1.1. General Inference Parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-parameters">3.1.2. Model Parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="#training-the-models">3.1.3. Training the models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#creating-new-models">3.2. Creating New Models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="san_inference.html">4. Inferring Galaxy Parameters (SAN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="cvae_inference.html">5. Inferring Galaxy Parameters (CVAE)</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #FFFFFF" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">AGN Finder Documentation</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li><span class="section-number">3. </span>Inference Overview</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/inference.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="inference-overview">
<span id="inference"></span><h1><span class="section-number">3. </span>Inference Overview<a class="headerlink" href="#inference-overview" title="Permalink to this headline"></a></h1>
<p>The task of inferring physical galaxy parameters from photometric observations
can be seen as that of learning a mapping <span class="math notranslate nohighlight">\(f : \mathcal{X} \to
\Theta\)</span>, where <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> is the space of
<span class="math notranslate nohighlight">\(n\)</span>-dimensional photometric observations (corresponding to <span class="math notranslate nohighlight">\(n\)</span>
filters), and <span class="math notranslate nohighlight">\(\Theta\)</span> is the space of physical parameters, such
as mass, star formation, E(B-V), AGN disk inclination and so forth.</p>
<p>Since the photometric observations <span class="math notranslate nohighlight">\(\mathbf{x}\in\mathcal{X}\)</span> alone are
unlikely to be sufficient to constrain the full range of physical parameters
<span class="math notranslate nohighlight">\(\theta \in \Theta\)</span> that we’d like to infer, we resolve to output
distributions physical parameters, conditioned on the information in the
photometric observations. That is, the mapping <span class="math notranslate nohighlight">\(f\)</span> is one-to-many, and a
reasonable way to deal with this is to work with distributions over the outputs
<span class="math notranslate nohighlight">\(p(\theta \vert \mathbf{x})\)</span></p>
<p>From the simulation section, we generated a dataset of <span class="math notranslate nohighlight">\((\theta,
\mathbf{x})\)</span> pairs, <span class="math notranslate nohighlight">\(\mathcal{D} = \big\{(\theta_{i},
\mathbf{x}_{i})\big\}_{i=1}^{N}\)</span>, giving us a fairly standard supervised machine
learning setup.</p>
<p>We can appeal to the broad machine learning literature which presents many ways
to tackle this problem, for instance using generative models or autoregressive
models. Accordingly, to avoid a clash of notation, we will henceforth denote the
physical galaxy parameters as <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> (previously <span class="math notranslate nohighlight">\(\theta\)</span>).
This is to match the machine learning nomenclature of denoting the outputs to be
predicted as <span class="math notranslate nohighlight">\(\mathbf{y}\)</span>, and the model parameters as <span class="math notranslate nohighlight">\(\theta\)</span>. The
inputs remain <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>.</p>
<section id="using-the-models">
<h2><span class="section-number">3.1. </span>Using the Models<a class="headerlink" href="#using-the-models" title="Permalink to this headline"></a></h2>
<p>In line with this program’s conventions of using configuration classes rather
than command-line arguments, all the options for running inference can be set in
the <code class="docutils literal notranslate"><span class="pre">config.py</span></code> file.</p>
<p>There are two main classes to bear in mind:</p>
<section id="general-inference-parameters">
<h3><span class="section-number">3.1.1. </span>General Inference Parameters<a class="headerlink" href="#general-inference-parameters" title="Permalink to this headline"></a></h3>
<p>Models in this program are equipped with a <code class="docutils literal notranslate"><span class="pre">trainmodel</span></code> method, which provides
a consistent way to train different models. This method’s parameters are
contained in the <code class="docutils literal notranslate"><span class="pre">InferenceParams</span></code> class (the base class for this is defined
in <code class="docutils literal notranslate"><span class="pre">agnfinder/inference/inference.py</span></code>).</p>
<dl class="py class">
<dt class="sig sig-object py" id="InferenceParams">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">InferenceParams</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ConfigClass</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#InferenceParams" title="Permalink to this definition"></a></dt>
<dd><p>General parameters for the inference code.</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>model_t</em>) – The model to use for inference.</p></li>
<li><p><strong>split_ratio</strong> (<em>int</em>) – The dataset train/test split ratio.</p></li>
<li><p><strong>logging_frequency</strong> (<em>int</em>) – How often (in iterations) to output logs during training.</p></li>
<li><p><strong>dataset_loc</strong> (<em>str</em>) – Path to a <code class="docutils literal notranslate"><span class="pre">hdf5</span></code> file or directory of <code class="docutils literal notranslate"><span class="pre">hdf5</span></code> files.</p></li>
<li><p><strong>retrain_model</strong> (<em>bool</em>) – Whether to re-train an identically configured model.</p></li>
<li><p><strong>overwrite_results</strong> (<em>bool</em>) – Whether to overwrite results from identical model.</p></li>
</ul>
</dd>
<dt class="field-even">Example</dt>
<dd class="field-even"><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">InferenceParams</span><span class="p">(</span><span class="n">inference</span><span class="o">.</span><span class="n">InferenceParams</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">model</span><span class="p">:</span> <span class="n">model_t</span> <span class="o">=</span> <span class="n">san</span><span class="o">.</span><span class="n">SAN</span>
<span class="gp">... </span>    <span class="n">split_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="gp">... </span>    <span class="n">logging_frequency</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="gp">... </span>    <span class="n">dataset_loc</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;./data/cubes/photometry_simulation.hdf5&#39;</span>
<span class="gp">... </span>    <span class="n">retrain_model</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
<span class="gp">... </span>    <span class="n">overwrite_results</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<p>Most argument names along with their corresponding type should be self-explanatory.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">dataset_loc</span></code> property should point to the output of a simulation run
(that is, the output of running <code class="docutils literal notranslate"><span class="pre">make</span> <span class="pre">sim</span></code>). Please see the <a class="reference external" href="/sampling.html">Photometry
Sampling</a> section for more information about this.</p>
<p>When a model is initialised, a descriptive name is generated based on its
parameters. If the training method (<code class="docutils literal notranslate"><span class="pre">trainmodel</span></code>, see below) is called on a
model with identical parameters to a previously trained and saved model, and
the <code class="docutils literal notranslate"><span class="pre">retrain_model</span></code> argument is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, then we attempt to load (the
<code class="docutils literal notranslate"><span class="pre">state_dict</span></code> of) this previous identical model instead of training the model
immediately. If loading fails for some reason (e.g. the file does not exist),
then training proceeds as normal.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">retrain_model</span> <span class="pre">==</span> <span class="pre">True</span></code>, then the <code class="docutils literal notranslate"><span class="pre">overwrite_results</span></code> argument specifies
what to do when saving the resulting model—if set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, then the
previously saved model will be overwritten. If set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, then a number
is appended to the current model’s name to make it unique.</p>
</section>
<section id="model-parameters">
<h3><span class="section-number">3.1.2. </span>Model Parameters<a class="headerlink" href="#model-parameters" title="Permalink to this headline"></a></h3>
<p>While each model has slightly different requirements for its parameterisation
(for instance, the its architecture must be specified), there are some common
parameters which are shared across all models in the codebase.</p>
<p>To reflect this, model parameters inherit a base <a class="reference internal" href="#ModelParams" title="ModelParams"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelParams</span></code></a> class, which
specifies things such as the datatype, device memory to use and so forth.</p>
<dl class="py class">
<dt class="sig sig-object py" id="ModelParams">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">ModelParams</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ConfigClass</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ModelParams" title="Permalink to this definition"></a></dt>
<dd><p>General parameters for the inference code.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>epochs</strong> (<em>int</em>) – The number of epochs to train this model for.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em>) – The mini-batch size.</p></li>
<li><p><strong>dtype</strong> (<em>torch.dtype</em>) – PyTorch data type to use in model.</p></li>
<li><p><strong>device</strong> (<em>torch.device</em>) – Device (and device memory) to use.</p></li>
<li><p><strong>cond_dim</strong> (<em>int</em>) – Dimension of conditioning data (e.g. photometry)</p></li>
<li><p><strong>data_dim</strong> (<em>int</em>) – Dimension of output data (e.g. physical params)</p></li>
</ul>
</dd>
</dl>
<p>The following example contains a minimal concrete instance of <a class="reference internal" href="#ModelParams" title="ModelParams"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelParams</span></code></a>
(real models are likely to require additional parameters).</p>
<dl class="field-list">
<dt class="field-odd">Example</dt>
<dd class="field-odd"><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">class</span> <span class="nc">ExampleModelParams</span><span class="p">(</span><span class="n">ModelParams</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span>
<span class="gp">... </span>    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span>
<span class="gp">... </span>    <span class="n">dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
<span class="gp">... </span>    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">cond_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span>
<span class="gp">... </span>    <span class="n">data_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">9</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<p>Since all models are concerned with learning a distribution <span class="math notranslate nohighlight">\(p(\mathbf{y} \vert
\mathbf{x})\)</span>, for <span class="math notranslate nohighlight">\(\mathbf{y} \in \mathbb{R}^{N}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{x}
\in \mathbb{R}^{M}\)</span>, we can reliably set parameters <code class="docutils literal notranslate"><span class="pre">data_dim</span> <span class="pre">=</span> <span class="pre">N</span></code> and
<code class="docutils literal notranslate"><span class="pre">cond_dim</span> <span class="pre">=</span> <span class="pre">M</span></code> for all models.</p>
<p><strong>Aside</strong>:</p>
<blockquote>
<div><p>At first, putting <code class="docutils literal notranslate"><span class="pre">epochs</span></code> in the <a class="reference internal" href="#ModelParams" title="ModelParams"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelParams</span></code></a> (instead of the
<code class="docutils literal notranslate"><span class="pre">InferenceParams</span></code>) might seem to commit a ‘type error’: <cite>surely the training
duration has more to do with the training procedure than the model itself?</cite> The
<code class="docutils literal notranslate"><span class="pre">batch_size</span></code> parameter might also seem similarly misplaced. Since these
parameters have a large effect on model performance, I claim that they
should be treated similarly to architectural parameters, and are therefore
associated with a model.</p>
<p>For instance, when we come to load a trained model, we <cite>do</cite> care how
long it was trained for, therefore it makes more sense to associate this
parameter with the model itself; treating it as a model parameter rather than
merely a parameter of the training procedure.</p>
</div></blockquote>
</section>
<section id="training-the-models">
<h3><span class="section-number">3.1.3. </span>Training the models<a class="headerlink" href="#training-the-models" title="Permalink to this headline"></a></h3>
<p>To train a model, first ensure that you have correctly set the model and
inference parameters. Note that these configuration classes needn’t necessarily
be the ones in <code class="docutils literal notranslate"><span class="pre">config.py</span></code>—you are free to define new configuration classes
anywhere in the code.</p>
<p>You will also need a dataset loaded to train the model on. A utility function
(<code class="docutils literal notranslate"><span class="pre">utils.load_simulated_data</span></code>) is available to help with this.</p>
<p>You can now initialise a model by passing the initialised model parameters to
your model’s constructor. Finally the <code class="docutils literal notranslate"><span class="pre">trainmodel</span></code> method can be called to
run the training procedure.</p>
<p>Note that models are automatically saved to disk after a training run. If you
are re-training an identical parametrised model, the code will first attempt to
load an existing saved model before falling back to running the training
procedure.</p>
<p>The following is a full example, using the <a class="reference external" href="san_inference.html">SAN</a> model:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">agnfinder.nbutils</span> <span class="k">as</span> <span class="nn">nbu</span>

<span class="c1"># Configure the logger (defaults to INFO-level logs)</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">configure_logging</span><span class="p">()</span>

<span class="c1"># Initialise the inference, and model parameters; defined in config.py</span>
<span class="n">ip</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">InferenceParams</span><span class="p">()</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">cfg</span><span class="o">.</span><span class="n">SANParams</span><span class="p">()</span>

<span class="c1"># Get the dataloaders for training and testing</span>
<span class="n">train_loader</span><span class="p">,</span> <span class="n">test_loader</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">load_simulated_data</span><span class="p">(</span>
    <span class="n">path</span><span class="o">=</span><span class="n">ip</span><span class="o">.</span><span class="n">dataset_loc</span><span class="p">,</span>
    <span class="n">split_ratio</span><span class="o">=</span><span class="n">ip</span><span class="o">.</span><span class="n">split_ratio</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">sp</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">normalise_phot</span><span class="o">=</span><span class="n">utils</span><span class="o">.</span><span class="n">normalise_phot_np</span><span class="p">,</span>
    <span class="n">transforms</span><span class="o">=</span><span class="p">[</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
    <span class="p">])</span>
<span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Created data loaders&#39;</span><span class="p">)</span>

<span class="c1"># Initialise the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SAN</span><span class="p">(</span><span class="n">sp</span><span class="p">)</span>
<span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Initialised SAN model&#39;</span><span class="p">)</span>

<span class="c1"># Run the training procedure</span>
<span class="n">model</span><span class="o">.</span><span class="n">trainmodel</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">ip</span><span class="p">)</span>
<span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Trained SAN model&#39;</span><span class="p">)</span>

<span class="c1"># (Example: use the model for something)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">nbu</span><span class="o">.</span><span class="n">new_sample</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>
<span class="n">posterior_samples</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;Successfully sampled from model&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="creating-new-models">
<h2><span class="section-number">3.2. </span>Creating New Models<a class="headerlink" href="#creating-new-models" title="Permalink to this headline"></a></h2>
<p>To ensure that there are consistent interfaces for all the models (to the
benefit of users), and that common code is not duplicated between models (to the
benefit of developers), all the models implemented in the codebase inherit from
an abstract <a class="reference internal" href="#Model" title="Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></a> class (found in <code class="docutils literal notranslate"><span class="pre">agnfinder/inference/inference.py:Model</span></code>).</p>
<p>Put simply, to create a new model, inherit the <a class="reference internal" href="#Model" title="Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></a> class and ensure that
you have implemented all the abstract properties and methods.</p>
<p>The following shows the constructor, and abstract methods of the <a class="reference internal" href="#Model" title="Model"><code class="xref py py-class docutils literal notranslate"><span class="pre">Model</span></code></a>
class.</p>
<dl class="py class">
<dt class="sig sig-object py" id="Model">
<em class="property"><span class="pre">class</span> </em><span class="sig-name descname"><span class="pre">Model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">torch.nn.Module</span></em>, <em class="sig-param"><span class="pre">ABC</span></em><span class="sig-paren">)</span><a class="headerlink" href="#Model" title="Permalink to this definition"></a></dt>
<dd><p>Base model class for AGNFinder</p>
<dl class="py method">
<dt class="sig sig-object py" id="Model.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mp</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#ModelParams" title="ModelParams"><span class="pre">ModelParams</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">overwrite_results</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">logging_callbacks</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">list</span><span class="p"><span class="pre">[</span></span><span class="pre">Callable</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">[]</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#Model.__init__" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>mp</strong> (<a class="reference internal" href="#ModelParams" title="ModelParams"><em>ModelParams</em></a>) – The model parameters.</p></li>
<li><p><strong>overwrite_results</strong> (<em>bool</em>) – Overwrite previous results when saving.</p></li>
<li><p><strong>logging_callbacks</strong> (<em>list</em><em>[</em><em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="#Model" title="Model"><em>Model</em></a><em>]</em><em>, </em><em>None</em><em>]</em><em>]</em>) – Functions executed when logging.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Model.name">
<span class="sig-name descname"><span class="pre">name</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#Model.name" title="Permalink to this definition"></a></dt>
<dd><p>Returns a natural-language name for the model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Model.__repr__">
<span class="sig-name descname"><span class="pre">__repr__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#Model.__repr__" title="Permalink to this definition"></a></dt>
<dd><p>Give a natural-language description of the model. Do include information
such as <code class="docutils literal notranslate"><span class="pre">self.epochs</span></code>, <code class="docutils literal notranslate"><span class="pre">self.name</span></code> and <code class="docutils literal notranslate"><span class="pre">self.batch_size</span></code>, as well
as other architecture-specific details for your specific model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Model.fpath">
<span class="sig-name descname"><span class="pre">fpath</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="headerlink" href="#Model.fpath" title="Permalink to this definition"></a></dt>
<dd><p>Returns a file path to save the model to, which should be unique for
every different parametrisation of the model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Model.preprocess">
<span class="sig-name descname"><span class="pre">preprocess</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Tensor</span><span class="p"><span class="pre">,</span> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span></span></span><a class="headerlink" href="#Model.preprocess" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – The input (usually photometric observations)</p></li>
<li><p><strong>y</strong> (<em>Tensor</em>) – The output (usually physical galaxy parameters)</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The pre-processed parameters (e.g. cast to a specific data type, re-ordered or placed on a specific device’s memory.)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Model.trainmodel">
<span class="sig-name descname"><span class="pre">trainmodel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_loader</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">DataLoader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ip</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="overview.html#InferenceParams" title="InferenceParams"><span class="pre">InferenceParams</span></a></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="headerlink" href="#Model.trainmodel" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_loader</strong> (<em>DataLoader</em>) – The PyTorch DataLoader containing the training data.</p></li>
<li><p><strong>ip</strong> (<a class="reference internal" href="overview.html#InferenceParams" title="InferenceParams"><em>InferenceParams</em></a>) – Inference parameters containing details of the training procedure.</p></li>
</ul>
</dd>
</dl>
<p>Note that any additional model-specific arguments can also be provided.</p>
<p>This method has a decorator applied in the superclass (which is
inherited by all sub-classes) which takes care of saving the trained
model to disk (using <a class="reference internal" href="#Model.fpath" title="Model.fpath"><code class="xref py py-class docutils literal notranslate"><span class="pre">Model.fpath</span></code></a>), as well as loading up an
existing model rather than repeating training.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="Model.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_samples</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tensor</span></span></span><a class="headerlink" href="#Model.sample" title="Permalink to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>Tensor</em>) – The conditioning data, <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>.</p></li>
<li><p><strong>n_samples</strong> (<em>int</em>) – The number of samples to draw from the posterior.</p></li>
</ul>
</dd>
</dl>
<p>A convenience method for drawing (conditional) samples from <span class="math notranslate nohighlight">\(p(\mathbf{y} \vert
\mathbf{x})\)</span> for a single conditioning point.</p>
<p>Since different models may require additional parameters to arguments to
perform the sampling, these can be provided using the <code class="docutils literal notranslate"><span class="pre">args</span></code> and
<code class="docutils literal notranslate"><span class="pre">kwargs</span></code> parameters.</p>
<p>This is the only function pertaining to the actual use of the models
which is required to be consistent across models. Individual models may
provide different methods to use them.</p>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="sampling.html" class="btn btn-neutral float-left" title="2. Photometry Sampling" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="san_inference.html" class="btn btn-neutral float-right" title="4. Inferring Galaxy Parameters (SAN)" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>