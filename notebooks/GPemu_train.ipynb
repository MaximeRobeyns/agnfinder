{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import h5py\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import GPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA decomposition\n",
    "\n",
    "Dimensionality reduction using unsupervised PCA. Model is pickled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_reduction(X, ncomp=10):\n",
    "    \"\"\"\n",
    "    Input parameters :\n",
    "    - X : 1-D flatten data (nsamp * imsize)\n",
    "    - ncomp : Dimension of the subspace\n",
    "\n",
    "    Output :\n",
    "    - pca : PCA model\n",
    "    - weights : \n",
    "    \"\"\"\n",
    "    \n",
    "    print('Performing dimensionality reduction ...')\n",
    "\n",
    "    # PCA fitting\n",
    "    pca = PCA(n_components=ncomp)\n",
    "    weights = pca.fit_transform(X)\n",
    "    basis = pca.components_\n",
    "\n",
    "    # Plot cumsum(explained_variance) versus component\n",
    "    plt.figure(234)\n",
    "    plt.semilogy(pca.explained_variance_ratio_*100, 's-')\n",
    "    plt.ylabel('Explained Variance (%)', size=20)\n",
    "    plt.xticks(size=20)\n",
    "    plt.xlabel('Component', size=20)\n",
    "    plt.yticks(size=20)\n",
    "    plt.show()\n",
    "\n",
    "    print('Explained variance: '+str(round(np.cumsum(pca.explained_variance_ratio_)[-1]*100, 2))+' %.')\n",
    "\n",
    "    with open('pcaModel.pickle', 'wb') as handle:\n",
    "        pickle.dump(pca, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return pca, weights, basis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP fitting\n",
    "\n",
    "GP(x_values, y_values) is fitted. Trained model is picked as saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gp_fit(weights, params):\n",
    "    \"\"\"\n",
    "    Learns the GP related to the weigths matrix\n",
    "    Input :\n",
    "    - weights : From PCA\n",
    "    - params : x-values\n",
    "\n",
    "    Output :\n",
    "    - model : GP model\n",
    "    - tmean, tmult : Rescaling factors\n",
    "    \"\"\"\n",
    "    params, tmean, tmult = rescale(params)\n",
    "\n",
    "    # Set the kernel\n",
    "    # kernel = GPy.kern.Matern52(input_dim=params.shape[1], variance=.1, lengthscale=.1)\n",
    "    kernel = GPy.kern.Matern52(input_dim=params.shape[1])\n",
    "\n",
    "    # GP Regression\n",
    "    model = GPy.models.GPRegression(params, weights, kernel=kernel)\n",
    "    model.optimize()\n",
    "\n",
    "    # Save model\n",
    "    nparams = params.shape[1]\n",
    "    ntrain = weights.shape[1]\n",
    "    model.save_model('gpfit_'+str(ntrain)+'_'+str(nparams), compress=True, save_data=True)\n",
    "    return model, tmean, tmult\n",
    "\n",
    "\n",
    "def gp_predict(model, params):\n",
    "    \"\"\"\n",
    "    Predicts the weights matrix to feed inverse PCA from physical parameters.\n",
    "\n",
    "    Input :\n",
    "    - model : GP model\n",
    "    - params : physical parameters (flux, radius, shear profile, psf fwhm)\n",
    "\n",
    "    Output :\n",
    "    - predic[0] : predicted weights\n",
    "    \"\"\"\n",
    "    predict = model.predict(params)\n",
    "    return predict[0]\n",
    "\n",
    "\n",
    "def emulator(pca_model, gp_model, params):\n",
    "    \"\"\"\n",
    "    Emulates new images from physical parameters.\n",
    "\n",
    "    Input :\n",
    "    - pca : PCA model\n",
    "    - gp_model : GP model\n",
    "    - params : physical parameters (flux, radius, shear profile, psf fwhm)\n",
    "\n",
    "    Output :\n",
    "    - reconstructed : Emulated image\n",
    "    \"\"\"\n",
    "    # Weights prediction\n",
    "    params = np.expand_dims(params, axis = 0)\n",
    "    pred_weights = gp_predict(gp_model, params)\n",
    "\n",
    "    # Inverse PCA (pred_weights * basis + mean)\n",
    "    reconstructed = pca_model.inverse_transform(pred_weights)\n",
    "    return reconstructed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_loc = \"/Users/nramachandra/Desktop/Projects/AGNfinder/FSPS/\"\n",
    "\n",
    "with h5py.File(save_loc + 'fsps_cache.hdf5', 'r') as f:\n",
    "   X_loaded = f['fsps_cache']['X'][...]\n",
    "   Y_loaded = f['fsps_cache']['Y'][...] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## logging and clipping\n",
    "# X_loaded = np.log10(X_loaded)\n",
    "Y_loaded = np.log10(Y_loaded[:, 100:])\n",
    "\n",
    "# ### rescaling \n",
    "y_mean = np.mean(Y_loaded, axis=0)\n",
    "y_mult = np.max(Y_loaded - y_mean, axis=0)\n",
    "\n",
    "y_train = (Y_loaded - y_mean)/y_mult\n",
    "\n",
    "# ### rescaling \n",
    "x_mean = np.mean(X_loaded, axis=0)\n",
    "x_mult = np.max(X_loaded - x_mean, axis=0)\n",
    "\n",
    "x_train = (X_loaded - x_mean)/x_mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model, pca_weights, pca_basis = pca_reduction(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting PC weights \n",
    "\n",
    "Scatter plot to see dependence on x_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (7,6))\n",
    "plt.scatter(pca_weights[:, 0], pca_weights[:, 1], s=1, c= np.log10(X_loaded[:,0]))\n",
    "plt.ylabel('Weight '+str(0), size=25)\n",
    "plt.xlabel('Weight '+str(1), size=25)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (7,6))\n",
    "plt.scatter(pca_weights[:, 0], pca_weights[:, 2], s=1, c= np.log10(X_loaded[:,1]))\n",
    "plt.ylabel('Weight '+str(0), size=25)\n",
    "plt.xlabel('Weight '+str(2), size=25)\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (7,6))\n",
    "plt.scatter(pca_weights[:, 0], pca_weights[:, 3], s=1, c= np.log10(X_loaded[:,2]))\n",
    "plt.ylabel('Weight '+str(0), size=25)\n",
    "plt.xlabel('Weight '+str(3), size=25)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d    \n",
    "\n",
    "# %matplotlib notebook\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(111, projection = '3d')\n",
    "plt.scatter(pca_weights[:, 0], pca_weights[:, 2], pca_weights[:, 4], c= np.log10(X_loaded[:,0] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(y_train.T)\n",
    "# plt.yscale('log')\n",
    "# plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pcaModel.pickle', 'rb') as handle:\n",
    "    pca = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_fit(pca_weights, x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params = x_train[433]\n",
    "\n",
    "nparams = x_train.shape[1]\n",
    "ntrain = pca_weights.shape[1]\n",
    "\n",
    "gp_model = GPy.models.GPRegression.load_model('gpfit_'+str(ntrain)+'_'+str(nparams) + '.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_emu = emulator(pca_model, gp_model, new_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_emu.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1212)\n",
    "for i in range(100):\n",
    "    rand_idx = (np.random.randint(100, 2000))\n",
    "    rand_parmas = x_train[rand_idx]\n",
    "    y_emu = emulator(pca_model, gp_model, new_params)\n",
    "    y_true = y_train[rand_idx]\n",
    "    plt.plot(y_emu.T/y_true.T)\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu] *",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
