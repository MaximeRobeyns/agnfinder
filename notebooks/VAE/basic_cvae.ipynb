{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf8fca3-2809-4990-bed5-cac8e183b688",
   "metadata": {},
   "source": [
    "# Basic Conditional VAE\n",
    "\n",
    "**Author:** Maxime Robeyns (2021) <maximerobeyns@gmail.com>\n",
    "\n",
    "In this file, we train a CVAE on MNIST data. We use $y \\in [0, 1]^{784}$ to denote the flattened pixel data, and $x \\in \\{0, 1\\}^{10}$ to denote one-hot encoded MNIST image labels.\n",
    "\n",
    "The latent variable model is $p(y, z | x)$, where the encoder finds $\\hat{z} \\sim q(z | y, x)$, and the decoder is $\\hat{y} \\sim p(y | z, x)$. Following [Sohn et al., 2015](https://proceedings.neurips.cc/paper/2015/file/8d55a249e6baa5c06772297520da2051-Paper.pdf), the recognition network is the same as the prior network $q(z | x, y) = p(z | x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8fe11f-ee5d-4438-b46b-f54e8c59bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ffbc2a-afe6-46dd-b648-41ae59d76e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: # One-time setup\n",
    "    assert(_SETUP)\n",
    "except NameError:\n",
    "    while not '.git' in os.listdir():\n",
    "        os.chdir(\"../\")\n",
    "    device = t.device(\"cuda\") if t.cuda.is_available() else t.device(\"cpu\")\n",
    "    if device == t.device(\"cuda\"):\n",
    "        !nvidia-smi\n",
    "    else:\n",
    "        print('CUDA is unavailable; training on CPU.')\n",
    "    _SETUP = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a570f78c-2126-4d7b-a12b-33da6c959136",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e195932b-2759-44d0-8f19-8940a0e9ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(batch_size: int = 100) -> tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"(Down)load MNIST dataset in ./data/testdata, and return training and\n",
    "    test DataLoaders using specified batch_size.\n",
    "    \"\"\"\n",
    "\n",
    "    cuda_kwargs = {'num_workers': 2} #, 'pin_memory': True}\n",
    "    train_kwargs = {'batch_size': batch_size, 'shuffle': True} | cuda_kwargs\n",
    "    test_kwargs = {'batch_size': batch_size, 'shuffle': False} | cuda_kwargs\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    train_set = datasets.MNIST('./data/testdata', train=True, download=True, \n",
    "                               transform=transform)\n",
    "    test_set = datasets.MNIST('./data/testdata', train=False, download=True, \n",
    "                              transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_set, **train_kwargs)\n",
    "    test_loader = DataLoader(test_set, **test_kwargs)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "def onehot(idx: t.Tensor, n: int) -> t.Tensor:\n",
    "    \"\"\"Turns an index into a one-hot encoded vector, of length n\"\"\"\n",
    "    assert t.max(idx).item() < n\n",
    "    \n",
    "    if idx.dim() == 1:\n",
    "        idx = idx.unsqueeze(1)\n",
    "    onehot = t.zeros(idx.size(0), n).to(idx.device)\n",
    "    onehot.scatter_(1, idx, 1)\n",
    "    \n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391bf436-3a11-435a-919d-099e8ef61519",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \"\"\"Variational AutoEncoder\"\"\"\n",
    "    \n",
    "    def __init__(self, encoder_layers: list[int], latent_size: int,\n",
    "                 decoder_layers: list[int], num_labels: int = 0):\n",
    "        super().__init__()\n",
    "        assert num_labels > 0\n",
    "        self.latent_size = latent_size\n",
    "        self.encoder = Encoder(encoder_layers, latent_size, num_labels)\n",
    "        self.decoder = Decoder(decoder_layers, latent_size, num_labels)\n",
    "        \n",
    "    def forward(self, y: t.Tensor, x: t.Tensor) -> tuple[\n",
    "        t.Tensor, t.Tensor, t.Tensor, t.Tensor]:\n",
    " \n",
    "        if y.dim() > 2:\n",
    "            y = y.view(-1, 28*28)\n",
    "        \n",
    "        # parameters for Gaussian latent distribution\n",
    "        means, log_var = self.encoder(y, x)\n",
    "        # reparametrised sampling of z\n",
    "        z = self.reparametrise(means, log_var)\n",
    "        # reconstruct input image (y), with binary pixel data in [0, 1].\n",
    "        recon_img = self.decoder(z, x)\n",
    "        \n",
    "        return recon_img, means, log_var, z\n",
    "    \n",
    "    def reparametrise(self, mu: t.Tensor, log_var: t.Tensor) -> t.Tensor:\n",
    "        std = t.exp(0.5 * log_var)\n",
    "        eps = t.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def inference(self, z: t.Tensor, x: t.Tensor) -> t.Tensor:\n",
    "        recon_img = self.decoder(z, x)\n",
    "        return recon_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5de166-a733-436f-bbc1-20b553c50195",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer_sizes: list[int], latent_size: int,\n",
    "                 num_labels: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        # input layer is flattened image + one-hot encoded label y in [0, 9]\n",
    "        layer_sizes[0] += num_labels\n",
    "        \n",
    "        self.MLP = nn.Sequential()\n",
    "        for i, (j, k) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "            self.MLP.add_module(name=f'L{i}', module=nn.Linear(j, k))\n",
    "            self.MLP.add_module(name=f'A{i}', module=nn.ReLU())\n",
    "        \n",
    "        # no output activation function needed for latent distribution params\n",
    "        self.linear_means = nn.Linear(layer_sizes[-1], latent_size)\n",
    "        self.linear_log_var = nn.Linear(layer_sizes[-1], latent_size)\n",
    "        \n",
    "    def forward(self, y: t.Tensor, x: t.Tensor) -> tuple[t.Tensor, t.Tensor]:\n",
    "        # The notation of using x to denote inputs, and y to denote outputs is\n",
    "        # slightly unusual and 'backward' during the encoding step.\n",
    "        \n",
    "        x = onehot(x, n=10)\n",
    "        y = t.cat((y, x), -1)\n",
    "        \n",
    "        y = self.MLP(y)\n",
    "        means = self.linear_means(y)\n",
    "        log_vars = self.linear_log_var(y)\n",
    "        \n",
    "        return means, log_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5bfc6e-2838-4a7d-8f04-7142a15388e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layer_sizes: list[int], latent_size: int,\n",
    "                 num_labels: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.MLP = nn.Sequential()\n",
    "        input_size = latent_size + num_labels\n",
    "        \n",
    "        for i, (j, k) in enumerate(\n",
    "            zip([input_size]+layer_sizes[:-1], layer_sizes)):\n",
    "            self.MLP.add_module(name=f'L{i}', module=nn.Linear(j, k))\n",
    "            if i + 1 < len(layer_sizes):\n",
    "                self.MLP.add_module(name=f'A{i}', module=nn.ReLU())\n",
    "            else:\n",
    "                # sigmoid activation at output since pixels must be in [0, 1]\n",
    "                self.MLP.add_module(name='sigmoid', module=nn.Sigmoid())\n",
    "                \n",
    "    def forward(self, z: t.Tensor, x: t.Tensor) -> t.Tensor:\n",
    "        x = onehot(x, n=10)\n",
    "        z = t.cat((z, x), -1)\n",
    "        \n",
    "        y = self.MLP(z)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ae4f8c-3bb0-4b8a-bd7b-b61c6d95ea5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## VAE Loss Function\n",
    "\n",
    "The loss function comes from the variational lower bound; that is,\n",
    "\\begin{align*}\n",
    "    \\mathcal{L}_{\\text{CVAE}}(\\theta, \\phi; x, y) &= \n",
    "    \\mathbb{E}_{q_{\\phi}(z \\vert y, x)}\\left[\\log p_{\\theta}(y \\vert z, x)\\right]\n",
    "     - D_{\\text{KL}}\\left[q_{\\phi}(z \\vert y, x) \\Vert p_{\\theta}(z \\vert x)\\right] \\\\\n",
    "       &= \\mathbb{E}_{q_{\\phi}(z \\vert y, x)}\\big[\\log p_{\\theta}(y \\vert z, x) + \\log p_{\\theta}(z \\vert x) - \\log q_{\\phi}(z \\vert y, x)\\big] \\\\\n",
    "       &\\doteq \\mathbb{E}\\big[\\mathcal{L}_{\\text{logpy}} +\n",
    "       \\mathcal{L}_{\\text{logpz}} - \\mathcal{L}_{\\text{logqz}} \\big],\n",
    "\\end{align*}\n",
    "where the above consists of a reconstruction loss component ($\\mathbb{E}_{q_{\\phi}(z \\vert y, x)}\\big[\\log p_{\\theta}(y \\vert z, x)\\big] = p_{\\theta}(y \\vert x)$) which simply consists of the likelihood of the data under our model, as well as a KL divergence term. \n",
    "\n",
    "For the (log) likelihood, we are free to choose the most appropriate one for the data we are modelling; in this MNIST example, we could maximise a (factorised) Bernoulli likelihood (since $x \\in [0, 1]^{784}$), and this corresponds to minimising a binary cross entropy loss:\n",
    "$$\n",
    "\\tilde{\\mathcal{L}}_{\\text{logpy}} = \\sum_{i=1}^{784}\\hat{y}_{i}\\log y_{i} + (1-\\hat{y}_{i})\\log (1-y_{i}),\\hspace{0.5cm}\\text{where } \\hat{y} = p_{\\theta}(y \\vert z, x)\n",
    "$$\n",
    "We can also try out others (see cell below).\n",
    "\n",
    "\n",
    "For the other terms in the KL divergence, we use the result of the change of variables formula, along with the log determinant of the Jacobian to come to\n",
    "\\begin{align*}\n",
    "\\tilde{\\mathcal{L}}_{\\text{logpz}} &= - \\sum_{i}\\frac{1}{2}(x_{i}^2 + \\log(2\\pi) \\\\\n",
    "\\tilde{\\mathcal{L}}_{\\text{logqz}} &= - \\sum_{i}\\frac{1}{2}\\big(\\epsilon_{i}^2 + \\log (2\\pi)\\big) + \\log \\sigma_{i}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57b85a3-6cb8-4bec-b099-13153527a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_img: t.Tensor, img: t.Tensor, mean: t.Tensor,\n",
    "             log_var: t.Tensor) -> t.Tensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        recon_x, x: Size([mini_batch, 1, 28, 28])\n",
    "        mean, log_var: Size([mini_batch, latent_size])\n",
    "    \"\"\"\n",
    "    # Bernoilli likelihood (a little soft around the edges)\n",
    "    # NLL = t.nn.functional.binary_cross_entropy(\n",
    "    #     recon_img.view(-1, 28*28), img.view(-1, 28*28), reduction='sum')\n",
    "    \n",
    "    # Laplace likelihood (sharp numbers; more artifacting though)\n",
    "    # NLL = t.nn.functional.l1_loss(\n",
    "    #     recon_img.view(-1, 28*28), img.view(-1, 28*28), reduction='sum')\n",
    "\n",
    "    # (standard) Gaussian likelihood (similar to Bernoilli; perhaps slightly sharper?)\n",
    "    NLL = t.nn.functional.mse_loss(\n",
    "        recon_img.view(-1, 28*28), img.view(-1, 28*28), reduction='sum')\n",
    "    \n",
    "    # analytic KL between N(mean, log_var) and N(0,1)\n",
    "    DKL = -0.5 * t.sum(1 + log_var - mean.pow(2) - log_var.exp())\n",
    "    \n",
    "    return (NLL + DKL) / img.size(0)  # average over mini-batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99fefa-cd27-4b26-8ea6-22320e066495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader: DataLoader, vae: VAE, opt: t.optim.Optimizer, \n",
    "          epochs: int = 20, latent_size: int = 2, log_every: int = 1000):\n",
    "    for e in range(epochs):\n",
    "        for iteration, (y, x) in enumerate(train_loader):\n",
    "            \n",
    "            y, x = y.to(device), x.to(device)\n",
    "            recon_img, mean, log_var, z = vae(y, x)\n",
    "\n",
    "            loss = vae_loss(recon_img, y, mean, log_var)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            if iteration % log_every == 0 or iteration == len(train_loader)-1:\n",
    "                print(\"Epoch: {:02d}/{:02d}, Batch: {:03d}/{:d}, Loss {:9.4f}\".format(\n",
    "                    e, epochs, iteration, len(train_loader)-1, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0be5489-9720-4330-af3b-58f6b3586b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = load_mnist()\n",
    "vae = VAE(encoder_layers=[784, 256],\n",
    "          latent_size=2,\n",
    "          decoder_layers=[256, 784],\n",
    "          num_labels=10).to(device)\n",
    "opt = t.optim.Adam(vae.parameters(), lr=1e-3)\n",
    "train(train_loader, vae, opt, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31612d3-3210-4cfc-8b9c-b9c77f915b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(vae: VAE):\n",
    "    x = t.arange(0, 10).long().unsqueeze(1).to(device)\n",
    "    z = t.randn([x.size(0), vae.latent_size]).to(device)\n",
    "    # calls the decoder\n",
    "    y = vae.inference(z, x)\n",
    "    plt.figure()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for p in range(10):\n",
    "        plt.subplot(2, 5, p+1)\n",
    "        plt.text(0, 0, f'c={x[p].item():d}', color='black',\n",
    "                 backgroundcolor='white', fontsize=8)\n",
    "        plt.imshow(-y[p].view(28, 28).cpu().data.numpy(), cmap=plt.get_cmap('PuBu'))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce63431-60a8-446e-a274-9d9bcc527a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf055f1-31af-44f7-88ed-67e218a8b48c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agnvenv (Python 3.9)",
   "language": "python",
   "name": "agnvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
