{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7537c3c-208b-4e72-8cd2-5b908a653cc5",
   "metadata": {},
   "source": [
    "# Dark Energy Survey (DES) Colours Test\n",
    "\n",
    "In this notebook, we use the DES catalogue and calculate 'colours' (pairwise differences between filter values ('maggies') as inputs to the network.\n",
    "\n",
    "Colours are calculated as $\\mathcal{C} = \\big\\{ (f_{i} - f_{j}) | i, j \\in [1, N], i < j \\big\\}$, for filter values $\\mathbf{f} = [f_{1}, \\ldots, f_{N}]$.\n",
    "\n",
    "There are good reasons to believe that this won't do anything much (other than slow down the network). Since the magnitudes ('maggies') are already normalised as $\\hat{\\mathbf{f}} = \\log \\big(\\frac{\\mathbf{f} - \\overline{\\mathbf{f}}}{\\text{std}(\\mathbf{f})}\\big)$, the benefit of inputting the relative distance between filter values is minimal. Worse, the conditioning information is now $N(N-1)/2$ instead of $N$; growing as $O(N^2)$ for $N$ the number of filters, and this significantly slows down the network. Owing to the depth of the SAN, and the alternating widths / bottlenecks in the architecture, it is likely that the network learns good representations on its own, without us needing to compute the colours by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47473ca7-1068-4922-b04e-d24ee29a8549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.colors import to_rgb, to_rgba\n",
    "from typing import Type, Any\n",
    "from torchvision import transforms\n",
    "\n",
    "# TODO clean up these imports!\n",
    "import agnfinder\n",
    "import agnfinder.inference.san as san\n",
    "import agnfinder.inference.inference as inf\n",
    "\n",
    "from agnfinder import config as cfg\n",
    "from agnfinder import nbutils as nbu\n",
    "from agnfinder.types import ConfigClass, column_order\n",
    "from agnfinder.inference import SAN\n",
    "from agnfinder.inference.utils import load_simulated_data, normalise_phot_np, maggies_to_colours_np, get_colours_length\n",
    "\n",
    "try: # One-time setup\n",
    "    assert(_SETUP)\n",
    "except NameError:\n",
    "    cfg.configure_logging()\n",
    "    os.chdir(os.path.split(agnfinder.__path__[0])[0])\n",
    "    dtype = t.float32\n",
    "    device = t.device(\"cuda\") if t.cuda.is_available() else t.device(\"cpu\")\n",
    "    if device == t.device(\"cuda\"):\n",
    "        print(f'Using GPU for training')\n",
    "        # !nvidia-smi\n",
    "    else:\n",
    "        print(\"CUDA is unavailable; training on CPU.\")\n",
    "    _SETUP = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c233253e-51e6-4702-987f-2b53acb150d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceParams(inf.InferenceParams):\n",
    "    model: inf.model_t = san.SAN\n",
    "    logging_frequency: int = 10000\n",
    "    dataset_loc: str = './data/cubes/des_sample/photometry_simulation_40000000n_z_0p0000_to_6p0000.hdf5'\n",
    "    retrain_model: bool = False\n",
    "    overwrite_results: bool = True\n",
    "    \n",
    "ip = InferenceParams()\n",
    "fp = cfg.FreeParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8516893-46ca-4d0d-94a3-ac7585bb24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_1024, test_loader_1024 = load_simulated_data(\n",
    "    path=ip.dataset_loc,\n",
    "    split_ratio=ip.split_ratio,\n",
    "    batch_size=1024,\n",
    "    normalise_phot=normalise_phot_np,\n",
    "    transforms=[transforms.ToTensor()],\n",
    "    x_transforms=[maggies_to_colours_np]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd60a7b4-0ca6-4154-b122-84f02f64b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_10000, test_loader_10000 = load_simulated_data(\n",
    "    path=ip.dataset_loc,\n",
    "    split_ratio=ip.split_ratio,\n",
    "    batch_size=10000,\n",
    "    normalise_phot=normalise_phot_np,\n",
    "    transforms=[transforms.ToTensor()],\n",
    "    x_transforms=[maggies_to_colours_np]\n",
    ")\n",
    "logging.info('Data loading complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df4f5ca-e198-430d-b62b-83ae82e03fd8",
   "metadata": {},
   "source": [
    "## SAN with Mixture of Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216d25bc-528f-47dd-90c9-b129553eafa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoGSANParams(san.SANParams):\n",
    "    epochs: int = 2\n",
    "    batch_size: int = 1024\n",
    "    dtype: t.dtype = t.float32\n",
    "    \n",
    "    # cond_dim: int = 7  # x; dimension of photometry / colours\n",
    "    cond_dim: int = get_colours_length(7)  # x; number of colours\n",
    "    data_dim: int = 9  # dimensions of data of interest (e.g. physical params)\n",
    "    # module_shape: list[int] = [512, 512]  # shape of the network 'modules'\n",
    "    module_shape: list[int] = [64, 64]  # shape of the network 'modules'\n",
    "    sequence_features: int = 8  # features passed between sequential blocks\n",
    "    likelihood: Type[san.SAN_Likelihood] = san.MoG\n",
    "    likelihood_kwargs: dict[str, Any] = {'K': 10}\n",
    "    batch_norm: bool = True  # use batch normalisation in network?\n",
    "\n",
    "mgsp = MoGSANParams() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e8586-24a0-4654-a5aa-67c5ff71e1a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mogsan = san.SAN(mgsp)\n",
    "mogsan.trainmodel(train_loader_1024, ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b9dee-3b70-43b4-b1e7-8a181b9c0b13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs, true_ys = nbu.new_sample(test_loader_1024)\n",
    "xs = xs.to(device, dtype)\n",
    "true_ys = true_ys.to(dtype=dtype)\n",
    "\n",
    "n_samples = 10000\n",
    "with t.inference_mode():\n",
    "    start = time.time()\n",
    "    samples = mogsan.sample(xs, n_samples=n_samples).cpu()\n",
    "    sampling_time = (time.time() - start) * 1e3\n",
    "logging.info(f'Finished drawing {n_samples:,} samples in {sampling_time:.4f}ms.')\n",
    "logging.info('Plotting results...')\n",
    "\n",
    "lims = np.array([[0.,1.]]).repeat(len(column_order),0)\n",
    "nbu.plot_corner(samples=samples.numpy(), true_params=true_ys.cpu().numpy(), \n",
    "                lims=lims, labels=column_order, title='SAN on DES Catalogue with Colours',\n",
    "                description=str(mogsan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9c829-f581-4da2-a57b-7c5f41502e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, true_ys = nbu.new_sample(test_loader_10000, 10000)\n",
    "xs = xs.to(device, dtype)\n",
    "true_ys = true_ys.to(device, dtype)\n",
    "\n",
    "# samples per posterior\n",
    "N = 100\n",
    "\n",
    "with t.inference_mode():\n",
    "    xs, _ = mogsan.preprocess(xs, t.empty(xs.shape))\n",
    "    samples = mogsan.forward(xs.repeat_interleave(N, 0))\n",
    "logging.info('Finished sampling. Plotting')\n",
    "    \n",
    "true_ys = true_ys.repeat_interleave(N, 0).cpu().numpy()\n",
    "nbu.plot_posteriors(samples.cpu().numpy(), true_ys, title=\"SAN on DES Catalogue with Colours\",\n",
    "                    description=f'{mogsan}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agnvenv (Python 3.9)",
   "language": "python",
   "name": "agnvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
