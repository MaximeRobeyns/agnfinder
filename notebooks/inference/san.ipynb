{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7537c3c-208b-4e72-8cd2-5b908a653cc5",
   "metadata": {},
   "source": [
    "# Variations on the 'Sequential Autoregressive Network'\n",
    "\n",
    "This notebook is for trying out different architectural choices as well as different likelihood choices for the sequential autoregressive network (SAN) model.\n",
    "\n",
    "Variations include:\n",
    "\n",
    "- Removing the reparametrised sampling for the marginal likelihoods\n",
    "- Providing the conditioning data $\\mathbf{x}$ directly to the inputs of the sequential blocks.\n",
    "- Using mixture distributions for the marginals\n",
    "\n",
    "The diagram below illustrates this new architecture, with Gaussian mixtures for $p(y_{d} \\vert \\mathbf{y}_{<d}, \\mathbf{x})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3350558a-41a8-4846-a6db-8953ac0137b7",
   "metadata": {},
   "source": [
    "<img src=\"https://share.maximerobeyns.com/san.svg\" width=\"80%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47473ca7-1068-4922-b04e-d24ee29a8549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch as t\n",
    "\n",
    "import agnfinder\n",
    "import agnfinder.inference.san as san\n",
    "\n",
    "from typing import Type, Any\n",
    "from torchvision import transforms\n",
    "\n",
    "from agnfinder import config as cfg\n",
    "from agnfinder import nbutils as nbu\n",
    "from agnfinder.types import ConfigClass, column_order\n",
    "from agnfinder.inference import SAN\n",
    "from agnfinder.inference.utils import load_simulated_data, normalise_phot_np\n",
    "\n",
    "try: # One-time setup\n",
    "    assert(_SETUP)\n",
    "except NameError:\n",
    "    cfg.configure_logging()\n",
    "    os.chdir(os.path.split(agnfinder.__path__[0])[0])\n",
    "    dtype = t.float32\n",
    "    device = t.device(\"cuda\") if t.cuda.is_available() else t.device(\"cpu\")\n",
    "    if device == t.device(\"cuda\"):\n",
    "        print(f'Using GPU for training')\n",
    "        # !nvidia-smi\n",
    "    else:\n",
    "        print(\"CUDA is unavailable; training on CPU.\")\n",
    "    _SETUP = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c233253e-51e6-4702-987f-2b53acb150d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceParams(ConfigClass):\n",
    "    epochs: int = 20\n",
    "    batch_size: int = 1024\n",
    "    split_ratio: float = 0.9\n",
    "    dtype: t.dtype = dtype\n",
    "    device: t.device = device\n",
    "    logging_frequency: int = 10000\n",
    "    dataset_loc: str = './data/cubes/40M_shuffled.hdf5'\n",
    "    retrain_model: bool = False  # Don't re-train an identical (existing) model\n",
    "    overwrite_results: bool = True  # If we do re-train an identical model, save it\n",
    "\n",
    "ip = InferenceParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8516893-46ca-4d0d-94a3-ac7585bb24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_1024, test_loader_1024 = load_simulated_data(\n",
    "    path=ip.dataset_loc,\n",
    "    split_ratio=ip.split_ratio,\n",
    "    batch_size=1024,\n",
    "    normalise_phot=normalise_phot_np,\n",
    "    transforms=[transforms.ToTensor()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd60a7b4-0ca6-4154-b122-84f02f64b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_10000, test_loader_10000 = load_simulated_data(\n",
    "    path=ip.dataset_loc,\n",
    "    split_ratio=ip.split_ratio,\n",
    "    batch_size=10000,\n",
    "    normalise_phot=normalise_phot_np,\n",
    "    transforms=[transforms.ToTensor()]\n",
    ")\n",
    "logging.info('Data loading complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a064cf45-d524-4a68-a28b-66a3159c1c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_san(sp: ConfigClass, ip: InferenceParams) -> SAN:\n",
    "    san = SAN(cond_dim=sp.cond_dim, data_dim=sp.data_dim, \n",
    "              module_shape=sp.module_shape, \n",
    "              sequence_features=sp.sequence_features, \n",
    "              likelihood=sp.likelihood, \n",
    "              likelihood_kwargs=sp.likelihood_kwargs, \n",
    "              batch_norm=sp.batch_norm, device=ip.device, \n",
    "              dtype=ip.dtype)\n",
    "    \n",
    "    savepath: str = san.fpath()\n",
    "    if not ip.retrain_model:\n",
    "        try:\n",
    "            logging.info(f'Attempting to load {san.likelihood.name()} SAN model from {savepath}')\n",
    "            san = t.load(savepath).to(ip.device, ip.dtype)\n",
    "            logging.info(f'Successfully loaded')\n",
    "            return san.cuda() if ip.device == t.device('cuda') else san\n",
    "        except:\n",
    "            logging.info(f'No model {savepath} found; training...')\n",
    "            \n",
    "    san.trainmodel(train_loader_1024, ip.epochs, ip.logging_frequency)\n",
    "    logging.info(f'Trained {san.likelihood.name()} SAN model')\n",
    "\n",
    "    t.save(san, san.fpath())\n",
    "    logging.info(f'Saved {san.likelihood.name()} SAN model as: {san.fpath()}')\n",
    "    return san.cuda() if ip.device == t.device('cuda') else san"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df4f5ca-e198-430d-b62b-83ae82e03fd8",
   "metadata": {},
   "source": [
    "## SAN with Mixture of Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216d25bc-528f-47dd-90c9-b129553eafa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoGSANParams(ConfigClass):\n",
    "    cond_dim: int = 8  # dimensions of conditioning info (e.g. photometry)\n",
    "    data_dim: int = 9  # dimensions of data of interest (e.g. physical params)\n",
    "    # TODO vary the width and depth\n",
    "    module_shape: list[int] = [32, 64, 32]  # shape of the network 'modules'\n",
    "    sequence_features: int = 8  # features passed between sequential blocks\n",
    "    likelihood_kwargs: dict[str, Any] = {'K': 10}\n",
    "    likelihood: Type[san.SAN_Likelihood] = san.MoG\n",
    "    lparams: int = 2  # number of parameers for likelihood p(y_d | y_<d, x)\n",
    "    batch_norm: bool = True  # use batch normalisation in network?\n",
    "\n",
    "mgsp = MoGSANParams() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e8586-24a0-4654-a5aa-67c5ff71e1a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mogsan = train_san(mgsp, ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b9dee-3b70-43b4-b1e7-8a181b9c0b13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs, true_ys = nbu.new_sample(test_loader_1024)\n",
    "xs = xs.to(device, dtype)\n",
    "true_ys = true_ys.to(dtype=dtype)\n",
    "\n",
    "n_samples = 10000\n",
    "with t.inference_mode():\n",
    "    start = time.time()\n",
    "    samples = mogsan.sample(xs, n_samples=n_samples).cpu()\n",
    "    sampling_time = (time.time() - start) * 1e3\n",
    "logging.info(f'Finished drawing {n_samples:,} samples in {sampling_time:.4f}ms.')\n",
    "logging.info('Plotting results...')\n",
    "\n",
    "description = f'{mogsan} trained for {ip.epochs} epochs (batch size {ip.batch_size})'\n",
    "\n",
    "lims = np.array([[0.,1.]]).repeat(len(column_order),0)\n",
    "nbu.plot_corner(samples=samples.numpy(), true_params=true_ys.cpu().numpy(), \n",
    "                lims=lims, labels=column_order, title='Gaussian Mixture \"Sequential Autoregressive Network\"',\n",
    "                description=description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9c829-f581-4da2-a57b-7c5f41502e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs, true_ys = nbu.new_sample(test_loader_10000, 8000)\n",
    "xs = xs.to(device, dtype)\n",
    "true_ys = true_ys.to(device, dtype)\n",
    "\n",
    "# samples per posterior\n",
    "N = 1000\n",
    "\n",
    "with t.inference_mode():\n",
    "    xs, _ = mogsan.preprocess(xs, t.empty(xs.shape))\n",
    "    samples = mogsan.forward(xs.repeat_interleave(N, 0))\n",
    "    \n",
    "true_ys = true_ys.repeat_interleave(N, 0).cpu().numpy()\n",
    "nbu.plot_posteriors(samples.cpu().numpy(), true_ys, title=\"Gaussian Mixture 'Sequential Autoregressive Network'\",\n",
    "                    description=f'{mogsan} trained for 5 epochs, batch size 1024.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a18fd9-f19c-4066-a433-b9c5adf2a54a",
   "metadata": {},
   "source": [
    "## Gaussian Baseline (without reparametrised sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd04f8f-85d4-4e3e-a2df-f8572bf9369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SANParams(ConfigClass):\n",
    "    cond_dim: int = 8  # dimensions of conditioning info (e.g. photometry)\n",
    "    data_dim: int = 9  # dimensions of data of interest (e.g. physical params)\n",
    "    module_shape: list[int] = [16, 32]  # shape of the network 'modules'\n",
    "    sequence_features: int = 4  # features passed between sequential blocks\n",
    "    likelihood: Type[san.SAN_Likelihood] = san.Gaussian\n",
    "    likelihood_kwargs = None\n",
    "    lparams: int = 2  # number of parameers for likelihood p(y_d | y_<d, x)\n",
    "    batch_norm: bool = True  # use batch normalisation in network?\n",
    "\n",
    "sp = SANParams() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41287fbb-cc5e-4963-acd0-0371b9742cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsan = train_san(sp, ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade663b4-ef0e-4f49-a4cc-cdff07f9c940",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, true_ys = nbu.new_sample(test_loader_1024)\n",
    "xs = xs.to(device, dtype)\n",
    "true_ys = true_ys.to(device, dtype)\n",
    "# true_ys = t.tensor([true_ys[i] for i in fgmm_param_idxs])\n",
    "\n",
    "n_samples = 10000\n",
    "with t.inference_mode():\n",
    "    start = time.time()\n",
    "    samples = gsan.sample(xs, n_samples=n_samples).cpu()\n",
    "    sampling_time = (time.time() - start) * 1e3\n",
    "logging.info(f'Finished drawing {n_samples:,} samples in {sampling_time:.4f}ms.')\n",
    "logging.info('Plotting results...')\n",
    "\n",
    "description = f'{gsan} trained for {ip.epochs} epochs (batch size {ip.batch_size})'\n",
    "\n",
    "lims = np.array([[0.,1.]]).repeat(len(column_order),0)\n",
    "nbu.plot_corner(samples=samples.numpy(), true_params=true_ys.cpu().numpy(), \n",
    "                lims=lims, labels=column_order, title='Gaussian \"Sequential Autoregressive Network\"',\n",
    "                description=description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc7517-a8ed-4046-bf1c-238f9a13d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, true_ys = nbu.new_sample(test_loader_10000, 10000)\n",
    "xs = xs.to(device, dtype)\n",
    "true_ys = true_ys.to(device, dtype)\n",
    "\n",
    "# samples per posterior\n",
    "N = 1000\n",
    "\n",
    "with t.inference_mode():\n",
    "    xs, _ = gsan.preprocess(xs, t.empty(xs.shape))\n",
    "    samples = gsan.forward(xs.repeat_interleave(N, 0))\n",
    "    \n",
    "true_ys = true_ys.repeat_interleave(N, 0).cpu().numpy()\n",
    "nbu.plot_posteriors(samples.cpu().numpy(), true_ys, title=\"Gaussian 'Sequential Autoregressive Network'\",\n",
    "                   description=f'{gsan} trained for 5 epochs, batch size 1024.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6fc4f2-51ea-4c9f-a249-7b6c10a1fac1",
   "metadata": {},
   "source": [
    "## Mixture of StudentT Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9cd172-5eb6-4a84-a383-0572dddbd661",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoSTSANParams(ConfigClass):\n",
    "    cond_dim: int = 8  # dimensions of conditioning info (e.g. photometry)\n",
    "    data_dim: int = 9  # dimensions of data of interest (e.g. physical params)\n",
    "    module_shape: list[int] = [16, 32]  # shape of the network 'modules'\n",
    "    sequence_features: int = 4  # features passed between sequential blocks\n",
    "    likelihood_kwargs: dict[str, Any] = {'K': 5}\n",
    "    likelihood: Type[san.SAN_Likelihood] = san.MoST\n",
    "    batch_norm: bool = True  # use batch normalisation in network?\n",
    "\n",
    "mostsp = MoSTSANParams() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0338f4-545a-4c3c-ade7-244525da509c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mostsan = train_san(mostsp, ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7211a91-330f-4c38-a27a-f011a6e4d196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs, true_ys = nbu.new_sample(test_loader_1024)\n",
    "xs = xs.to(device, dtype)\n",
    "true_ys = true_ys.to(device, dtype)\n",
    "# true_ys = t.tensor([true_ys[i] for i in fgmm_param_idxs])\n",
    "\n",
    "n_samples = 10000\n",
    "with t.inference_mode():\n",
    "    start = time.time()\n",
    "    samples = mostsan.sample(xs, n_samples=n_samples).cpu()\n",
    "    sampling_time = (time.time() - start) * 1e3\n",
    "logging.info(f'Finished drawing {n_samples:,} samples in {sampling_time:.4f}ms.')\n",
    "logging.info('Plotting results...')\n",
    "\n",
    "description = f'{mostsan} trained for {ip.epochs} epochs (batch size {ip.batch_size})'\n",
    "\n",
    "lims = np.array([[0.,1.]]).repeat(len(column_order),0)\n",
    "nbu.plot_corner(samples=samples.numpy(), true_params=true_ys.cpu().numpy(), \n",
    "                lims=lims, labels=column_order, title='StudentT Mixture \"Sequential Autoregressive Network\"',\n",
    "                description=description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc6ef65-873f-4bd2-bf79-9ad13001d8a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs, true_ys = nbu.new_sample(test_loader_1024, 1000)\n",
    "xs = xs.to(device, dtype)\n",
    "true_ys = true_ys.to(device, dtype)\n",
    "\n",
    "# samples per posterior\n",
    "N = 100\n",
    "\n",
    "with t.inference_mode():\n",
    "    xs, _ = mostsan.preprocess(xs, t.empty(xs.shape))\n",
    "    samples = mostsan.forward(xs.repeat_interleave(N, 0))\n",
    "    \n",
    "true_ys = true_ys.repeat_interleave(N, 0).cpu().numpy()\n",
    "nbu.plot_posteriors(samples.cpu().numpy(), true_ys, title=\"StudentT Mixture 'Sequential Autoregressive Network'\",\n",
    "                   description=f'{mostsan} trained for 5 epochs, batch size 1024.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d96e2fe-c654-4f4b-99e9-5072d4330ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agnvenv (Python 3.9)",
   "language": "python",
   "name": "agnvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
