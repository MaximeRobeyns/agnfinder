{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7537c3c-208b-4e72-8cd2-5b908a653cc5",
   "metadata": {},
   "source": [
    "# Sequential Autoregressive Network results\n",
    "\n",
    "This notebook contains variations on the first 'SAN' models; in particular we use a larger (wider, but not deeper) network which gives better NLL scores during training, as well as seemingly improved predictive performance.\n",
    "\n",
    "The diagram below illustrates the architecture of the _Sequential Autoregressive Network_, with Gaussian mixtures for $p(y_{d} \\vert \\mathbf{y}_{<d}, \\mathbf{x})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3350558a-41a8-4846-a6db-8953ac0137b7",
   "metadata": {},
   "source": [
    "<img src=\"https://share.maximerobeyns.com/san.svg\" width=\"80%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47473ca7-1068-4922-b04e-d24ee29a8549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import to_rgb, to_rgba\n",
    "\n",
    "import agnfinder\n",
    "import agnfinder.inference.san as san\n",
    "\n",
    "from typing import Type, Any\n",
    "from torchvision import transforms\n",
    "\n",
    "from agnfinder import config as cfg\n",
    "from agnfinder import nbutils as nbu\n",
    "from agnfinder.types import ConfigClass, column_order\n",
    "from agnfinder.simulation import Simulator_f\n",
    "from agnfinder.inference import SAN\n",
    "from agnfinder.inference.utils import load_simulated_data, normalise_phot_np\n",
    "\n",
    "try: # One-time setup\n",
    "    assert(_SETUP)\n",
    "except NameError:\n",
    "    cfg.configure_logging()\n",
    "    os.chdir(os.path.split(agnfinder.__path__[0])[0])\n",
    "    dtype = t.float32\n",
    "    device = t.device(\"cuda\") if t.cuda.is_available() else t.device(\"cpu\")\n",
    "    if device == t.device(\"cuda\"):\n",
    "        print(f'Using GPU for training')\n",
    "        # !nvidia-smi\n",
    "    else:\n",
    "        print(\"CUDA is unavailable; training on CPU.\")\n",
    "    _SETUP = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c233253e-51e6-4702-987f-2b53acb150d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceParams(ConfigClass):\n",
    "    epochs: int = 20\n",
    "    batch_size: int = 1024\n",
    "    split_ratio: float = 0.9\n",
    "    dtype: t.dtype = dtype\n",
    "    device: t.device = device\n",
    "    logging_frequency: int = 10000\n",
    "    dataset_loc: str = './data/cubes/40M_shuffled.hdf5'\n",
    "    retrain_model: bool = False  # Don't re-train an identical (existing) model\n",
    "    overwrite_results: bool = True  # If we do re-train an identical model, save it\n",
    "\n",
    "ip = InferenceParams()\n",
    "fp = cfg.FreeParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8516893-46ca-4d0d-94a3-ac7585bb24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_1024, test_loader_1024 = load_simulated_data(\n",
    "    path=ip.dataset_loc,\n",
    "    split_ratio=ip.split_ratio,\n",
    "    batch_size=1024,\n",
    "    normalise_phot=normalise_phot_np,\n",
    "    transforms=[transforms.ToTensor()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd60a7b4-0ca6-4154-b122-84f02f64b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_10000, test_loader_10000 = load_simulated_data(\n",
    "    path=ip.dataset_loc,\n",
    "    split_ratio=ip.split_ratio,\n",
    "    batch_size=10000,\n",
    "    normalise_phot=normalise_phot_np,\n",
    "    transforms=[transforms.ToTensor()]\n",
    ")\n",
    "logging.info('Data loading complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a064cf45-d524-4a68-a28b-66a3159c1c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_san(sp: ConfigClass, ip: InferenceParams) -> SAN:\n",
    "    san = SAN(cond_dim=sp.cond_dim, data_dim=sp.data_dim, \n",
    "              module_shape=sp.module_shape, \n",
    "              sequence_features=sp.sequence_features, \n",
    "              likelihood=sp.likelihood, \n",
    "              likelihood_kwargs=sp.likelihood_kwargs, \n",
    "              batch_norm=sp.batch_norm, device=ip.device, \n",
    "              dtype=ip.dtype)\n",
    "    \n",
    "    savepath: str = san.fpath()\n",
    "    if not ip.retrain_model:\n",
    "        try:\n",
    "            logging.info(f'Attempting to load {san.likelihood.name()} SAN model from {savepath}')\n",
    "            san.load_state_dict(t.load(savepath))\n",
    "            logging.info(f'Successfully loaded')\n",
    "            return san.cuda() if ip.device == t.device('cuda') else san\n",
    "        except:\n",
    "            logging.info(f'Could not load model {savepath}; training...')\n",
    "            \n",
    "    san.trainmodel(train_loader_1024, ip.epochs, ip.logging_frequency)\n",
    "    logging.info(f'Trained {san.likelihood.name()} SAN model')\n",
    "\n",
    "    t.save(san.state_dict(), san.fpath())\n",
    "    logging.info(f'Saved {san.likelihood.name()} SAN model as: {san.fpath()}')\n",
    "    return san.cuda() if ip.device == t.device('cuda') else san"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df4f5ca-e198-430d-b62b-83ae82e03fd8",
   "metadata": {},
   "source": [
    "## SAN with Mixture of Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216d25bc-528f-47dd-90c9-b129553eafa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoGSANParams(ConfigClass):\n",
    "    cond_dim: int = 8  # dimensions of conditioning info (e.g. photometry)\n",
    "    data_dim: int = 9  # dimensions of data of interest (e.g. physical params)\n",
    "    # TODO vary the width and depth\n",
    "    module_shape: list[int] = [512, 512]  # shape of the network 'modules'\n",
    "    sequence_features: int = 8  # features passed between sequential blocks\n",
    "    likelihood_kwargs: dict[str, Any] = {'K': 10}\n",
    "    likelihood: Type[san.SAN_Likelihood] = san.MoG\n",
    "    lparams: int = 2  # number of parameers for likelihood p(y_d | y_<d, x)\n",
    "    batch_norm: bool = True  # use batch normalisation in network?\n",
    "\n",
    "mgsp = MoGSANParams() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e8586-24a0-4654-a5aa-67c5ff71e1a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mogsan = train_san(mgsp, ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b9dee-3b70-43b4-b1e7-8a181b9c0b13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs, true_ys = nbu.new_sample(test_loader_1024)\n",
    "xs = xs.to(device, dtype)\n",
    "true_ys = true_ys.to(dtype=dtype)\n",
    "\n",
    "n_samples = 10000\n",
    "with t.inference_mode():\n",
    "    start = time.time()\n",
    "    samples = mogsan.sample(xs, n_samples=n_samples).cpu()\n",
    "    sampling_time = (time.time() - start) * 1e3\n",
    "logging.info(f'Finished drawing {n_samples:,} samples in {sampling_time:.4f}ms.')\n",
    "logging.info('Plotting results...')\n",
    "\n",
    "description = f'{mogsan} trained for {ip.epochs} epochs (batch size {ip.batch_size})'\n",
    "\n",
    "lims = np.array([[0.,1.]]).repeat(len(column_order),0)\n",
    "nbu.plot_corner(samples=samples.numpy(), true_params=true_ys.cpu().numpy(), \n",
    "                lims=lims, labels=column_order, title='Gaussian Mixture \"Sequential Autoregressive Network\"',\n",
    "                description=description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9c829-f581-4da2-a57b-7c5f41502e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, true_ys = nbu.new_sample(test_loader_10000, 10000)\n",
    "xs = xs.to(device, dtype)\n",
    "true_ys = true_ys.to(device, dtype)\n",
    "\n",
    "# samples per posterior\n",
    "N = 100\n",
    "\n",
    "with t.inference_mode():\n",
    "    xs, _ = mogsan.preprocess(xs, t.empty(xs.shape))\n",
    "    samples = mogsan.forward(xs.repeat_interleave(N, 0))\n",
    "logging.info('Finished sampling. Plotting')\n",
    "    \n",
    "true_ys = true_ys.repeat_interleave(N, 0).cpu().numpy()\n",
    "nbu.plot_posteriors(samples.cpu().numpy(), true_ys, title=\"Sequential Autoregressive Network\",\n",
    "                    description=(f'{mogsan} \\ntrained for {ip.epochs} epochs, '\n",
    "                                 f'batch size {ip.batch_size} and '\n",
    "                                 f'{mgsp.likelihood_kwargs[\"K\"]} mixture components.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcecc8e6-378f-408c-abc5-1e793815f89a",
   "metadata": {},
   "source": [
    "## Posterior Plots\n",
    "\n",
    "Here we plot the simulated photometry from posterior parameter samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83895e2d-8d9f-476e-915b-b802546ce5eb",
   "metadata": {},
   "source": [
    "Now, we need to sample (a single) galaxy at random from the testing dataset, draw N ($\\approx 100$) samples from the posterior distribution over the y parameters resulting from SAN (keep hold of the parameters of this Gaussian mixture distribution), pass these through the simulator, and plot them in an opacity that corresponds to the likelihood of the original y sample under the GMM with the true $\\mathbf{x}$ values (the photometry) picked from the test dataset plotted in a dictinctive colour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1852bb9-8000-40ee-9355-91321d6dfc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = nbu.new_sample(test_loader_1024, 1)\n",
    "xs = xs.to(device, dtype).unsqueeze(0)\n",
    "\n",
    "N = 100\n",
    "\n",
    "with t.inference_mode():\n",
    "    xs, _ = mogsan.preprocess(xs, t.empty(xs.shape))\n",
    "    samples = mogsan.forward(xs.repeat_interleave(N, 0))\n",
    "    ll = mogsan.likelihood.log_prob(samples, mogsan.last_params).exp()\n",
    "\n",
    "def _scatter(ax: plt.Axes, xs: np.ndarray, ys: np.ndarray, alpha: np.ndarray):\n",
    "    r, g, b = to_rgb('#35b4db')\n",
    "    color = np.array([(r, g, b, a) for a in alpha])\n",
    "    ax.scatter(xs, ys, c=color, label='posterior samples')\n",
    "    \n",
    "plot_xs = t.arange(9).expand(N, -1).numpy().flatten()\n",
    "plot_ys = samples.cpu().numpy().flatten()\n",
    "plot_alpha = ((ll - ll.min()) / (ll.max() - ll.min())).cpu().numpy().flatten()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3), dpi=200)\n",
    "_scatter(ax, plot_xs, plot_ys, plot_alpha)\n",
    "ax.scatter(np.arange(0, 9), ys.cpu().numpy(), c='r', label='true values')\n",
    "ax.set_ylim(0, 1)\n",
    "plt.xticks(np.arange(0, 9), fp.raw_members, rotation=45)\n",
    "ax.set_xlabel('Parameters')\n",
    "ax.set_ylabel('Normalised Values')\n",
    "ax.set_title('Single Galaxy Parameter Samples')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agnvenv (Python 3.9)",
   "language": "python",
   "name": "agnvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
